{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ubo-92IPYxHW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "#from torcheval.metrics.functional import multiclass_f1_score\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C4s91egnZ31C"
   },
   "outputs": [],
   "source": [
    "data_path = '../Data/full dataset'\n",
    "small_data_path = '../Data/Small Data 1000'\n",
    "extra_small_data_path = '../Data/Small Dataset 200'\n",
    "figures_output_path = '../Outputs/figures'\n",
    "csv_outputs ='../Outputs/csv'\n",
    "models_output_path = '../Models'\n",
    "model_checkpoints_path = '../Models/checkpoints'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D6rK4xhOZNoO"
   },
   "outputs": [],
   "source": [
    "# Create transforms\n",
    "data_transforms = {'train': transforms.Compose([\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "                   'val': transforms.Compose([\n",
    "                      transforms.Resize((300, 300)),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "                   'test': transforms.Compose([\n",
    "                      transforms.Resize((300,300)),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tioRZ3Pbc-v2"
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "\n",
    "\n",
    "image_datasets = {x:datasets.ImageFolder(os.path.join(data_path, x), data_transforms[x]) for x in [ 'val', 'test']}\n",
    "image_datasets['train'] = datasets.ImageFolder(os.path.join(extra_small_data_path,'train'), data_transforms['train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m3cd5awfepCS"
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "\n",
    "dataloaders = {x:torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True) for x in ['train', 'val', 'test']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5ak3fFCjfr0U"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xh7ASKAPhL_G",
    "outputId": "87990bb0-51c8-4d7f-af34-9d9279c65bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in the dataset are:['0', '1', '2', '3', '4']\n",
      "Num batches in training dataset:63\n",
      "Num images in training dataset:1000\n",
      "Num batches in val dataset:363\n",
      "Num images in val dataset:5796\n",
      "Num batches in test dataset:363\n",
      "Num images in test dataset:5796\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classes in the dataset are:{class_names}\")\n",
    "\n",
    "print(f\"Num batches in training dataset:{len(dataloaders['train'])}\")\n",
    "print(f\"Num images in training dataset:{dataset_sizes['train']}\")\n",
    "\n",
    "print(f\"Num batches in val dataset:{len(dataloaders['val'])}\")\n",
    "print(f\"Num images in val dataset:{dataset_sizes['val']}\")\n",
    "\n",
    "print(f\"Num batches in test dataset:{len(dataloaders['test'])}\")\n",
    "print(f\"Num images in test dataset:{dataset_sizes['test']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMg6bOObi8WL"
   },
   "source": [
    "Resnet 50 <br>\n",
    "V2 weights are improved upon V1 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSkoMXHGiKW8",
    "outputId": "9376e0a4-9e83-4dd2-87b8-785a1508b0a5"
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "#model_conv = torchvision.models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "model_conv = torchvision.models.inception_v3(weights='Inception_V3_Weights.IMAGENET1K_V1')\n",
    "#model_conv = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')\n",
    "#model_conv = torchvision.models.efficientnet_v2_l(weights='EfficientNet_V2_L_Weights.IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yrrOsatpixJ1"
   },
   "outputs": [],
   "source": [
    "# Freeze layers in the model to prevent disturbing the weights\n",
    "for param in model_conv.parameters():\n",
    "    param.required_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "17I2rJ3SjgGu"
   },
   "outputs": [],
   "source": [
    "# Replace final layer with new one with 5 output nodes\n",
    "#n_inputs = model_conv.fc.in_features\n",
    "#model_conv.fc= nn.Linear(in_features=n_inputs, out_features=len(class_names))\n",
    "# For VGG16 it is movel_conv.classifier that is replaced\n",
    "#model_conv.classifier[-1] = nn.Linear(in_features=4096, out_features=len(class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "65_RcYr9sGmG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F23orGZrsL1g"
   },
   "outputs": [],
   "source": [
    "# Set up loss function and optimiser\n",
    "#model_conv = torch.load(os.path.join(models_output_path, 'ResNet50_2.pt'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_conv.fc.parameters(), lr=0.1, momentum=0.9)\n",
    "#optimizer = optim.SGD(model_conv.classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_sch = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "#f1 = F1Score(task=\"multiclass\", num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "clSRZdwXwZ_T",
    "outputId": "84640aca-2650-456b-d40d-4e4d5a7584c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss 14.000083923339844, train accuracy 25.600000381469727\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m     images\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     55\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 58\u001b[0m outputs\u001b[38;5;241m=\u001b[39m \u001b[43mmodel_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m loss\u001b[38;5;241m=\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m     60\u001b[0m iter_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/inception.py:166\u001b[0m, in \u001b[0;36mInception3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InceptionOutputs:\n\u001b[1;32m    165\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_input(x)\n\u001b[0;32m--> 166\u001b[0m     x, aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     aux_defined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_logits\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/inception.py:121\u001b[0m, in \u001b[0;36mInception3._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMixed_5b(x)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# N x 256 x 35 x 35\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMixed_5c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# N x 288 x 35 x 35\u001b[39;00m\n\u001b[1;32m    123\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMixed_5d(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/inception.py:211\u001b[0m, in \u001b[0;36mInceptionA.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 211\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/inception.py:200\u001b[0m, in \u001b[0;36mInceptionA._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m branch5x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch5x5_1(x)\n\u001b[1;32m    198\u001b[0m branch5x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch5x5_2(branch5x5)\n\u001b[0;32m--> 200\u001b[0m branch3x3dbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranch3x3dbl_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m branch3x3dbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch3x3dbl_2(branch3x3dbl)\n\u001b[1;32m    202\u001b[0m branch3x3dbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch3x3dbl_3(branch3x3dbl)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torchvision/models/inception.py:407\u001b[0m, in \u001b[0;36mBasicConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    405\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[1;32m    406\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/nn/functional.py:1455\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "train_loss=[]\n",
    "train_accuracy=[]\n",
    "val_loss=[]\n",
    "val_accuracy=[]\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    exp_lr_sch.step()\n",
    "    iterations=0\n",
    "    iter_loss=0.0\n",
    "    correct=0\n",
    "\n",
    "    model_conv.train()\n",
    "\n",
    "    for images, labels in dataloaders['train']:\n",
    "        images = Variable(images)\n",
    "        labels=Variable(labels)\n",
    "        if torch.cuda.is_available():\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs,_= model_conv(images)\n",
    "        loss=criterion(outputs, labels)\n",
    "        iter_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        correct+=(predicted==labels).sum()\n",
    "        iterations+=1\n",
    "\n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    train_iter_acc = 100*correct/dataset_sizes['train']\n",
    "    train_accuracy.append(train_iter_acc)\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch}, Loss {loss.item()}, train accuracy {train_iter_acc}\")\n",
    "    #torch.save(model_conv, os.path.join(models_output_path, 'Inception_200.pt'))\n",
    "    \"\"\"torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_conv.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, PATH)\n",
    "\"\"\"\n",
    "    if 1==1:\n",
    "        model_conv.eval()\n",
    "        test_loss=0.0\n",
    "        correct=0\n",
    "        iterations=0\n",
    "\n",
    "        for images, labels in dataloaders['val']:\n",
    "            images = Variable(images)\n",
    "            labels=Variable(labels)\n",
    "            if torch.cuda.is_available():\n",
    "                images=images.cuda()\n",
    "                labels=labels.cuda()\n",
    "\n",
    "\n",
    "            outputs= model_conv(images)\n",
    "            loss=criterion(outputs, labels)\n",
    "            iter_loss+=loss.item()\n",
    "            _, predicted = torch.max(outputs,1)\n",
    "            correct+=(predicted==labels).sum()\n",
    "            iterations+=1\n",
    "\n",
    "        val_acc = 100*correct/dataset_sizes['val']\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch}, Loss {loss.item()}, val accuracy {val_acc}\")\n",
    "        val_loss.append(iter_loss/iterations)\n",
    "        val_iter_acc = 100*correct/dataset_sizes['val']\n",
    "        val_accuracy.append(val_iter_acc)\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "kFAAN51wkVV7",
    "outputId": "c1f9ffb1-ba37-424b-a7a4-ec4ccb55e057",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_accuracy = [i.item() for i in train_accuracy]\n",
    "val_accuracy = [i.item() for i in val_accuracy]\n",
    "pd.DataFrame([train_loss, train_accuracy, val_loss, val_accuracy]).to_excel(os.path.join(figures_output_path, 'Inception_200_200_stats.xlsx'))\n",
    "pd.DataFrame([predicted, labels]).to_excel(os.path.join(figures_output_path, 'Inception_200_200_stats.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGpzVCyZQO0V",
    "outputId": "d8a7f6af-de21-46fb-dbdb-61d2a19bb892"
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMXBXCC1Ra5E"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu4FwG5OTjbl",
    "outputId": "a7162f1f-fe99-4b94-9ff1-c8eb7ba94656"
   },
   "outputs": [],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yAnCskWCzfFb",
    "outputId": "3a5fc5b3-019b-4421-9789-fe0113c8e905"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([train_loss, train_accuracy, val_loss, val_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7Q4jnD7uHjd",
    "outputId": "fdae057b-ad9e-42d4-a5fe-ff12f08ea70f"
   },
   "outputs": [],
   "source": [
    "model_conv(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ty5hV2bGmFzk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
